\documentclass[10pt,twocolumn]{article}
\usepackage{abstract}
\usepackage[hypcap]{caption}
\usepackage{color}
\usepackage{enumerate}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[bottom]{footmisc}

\nonstopmode

\hypersetup{hidelinks}

\newcommand{\term}[1]{{\textit{#1}}}
\newcommand{\bterm}[1]{{\textbf{\textit{#1}}}}
\newcommand{\code}[1]{{\texttt{#1}}}
\newcommand{\super}[1]{{\textsuperscript{#1}}}
\newcommand{\sub}[1]{{\textsubscript{#1}}}
\newcommand{\abs}[1]{{\ensuremath{\left\vert\,#1\,\right\vert}}}
\newcommand{\paren}[1]{{\ensuremath{\left(#1\right)}}}
\def\zero{\texttt{0}}
\def\one{\texttt{1}}
\def\bit{{\ensuremath{\{\zero,\one\}}}}
\def\ppt{\textit{PPT}}
\def\obf{\ensuremath{\mathcal{O}}}
\def\negl{\text{negl}}
\def\poly{\text{poly}}
\def\cind{{\ensuremath{\stackrel{c}{\approx}}}}
\def\Adv{\text{Adv}}
\def\qed{\hfill \ensuremath{\square}}
\def\vbb{\textsf{vbb}}
\def\sbvbb{\textsf{sb-vbb}}
\def\ssbvbb{\textsf{ssb-vbb}}

% title
\title{Algorithm obfuscation}
\date{}
\author{
  \begin{tabular}{c c c}
    Christopher Martin \\
    \small \tt{chris.martin@gatech.edu}
  \end{tabular}
}

\renewcommand{\thefootnote}{[\arabic{footnote}]}

% document
\begin{document}

  \thispagestyle{empty}

  \twocolumn[
  \maketitle
  \begin{onecolabstract}
    \begin{quote}\begin{quote}\begin{quote}
      This paper is a brief survey of literature on the topic of obfuscation of algorithms.
      Can software be mangled in a way that preserves its functionality while hiding its ``secret sauce''?
      Results describe specific classes of functions which can and cannot be obfuscated.
    \end{quote}\end{quote}\end{quote}
    \vspace{1em}
  \end{onecolabstract}
  ]

  \section{Introduction}

    \begin{quote}
      ``Anyone who has tried to determine what operation is accomplished by someone else's machine language
      program knows that $E$ itself (i.e., what $E$ does) can be hard to infer from an algorithm for $E$.''

      \hfill --- Diffie and Hellman, 1976 \cite{newDirections}
    \end{quote}

    Software vendors sometimes take heuristic measures to scramble code in some way that makes it
    difficult for a reader to glean insight into how a program works. Often, intentional obfuscation
    is not even necessary toward this aim, because it is accomplished inadvertently by a compiler.
    Since the comprehensibility of software seem to decline without much effort, it is natural to
    wonder whether the loss of information can be formalized and used advantageously.

    If such obfuscation were possible, it would have the potential to yield some powerful results in cryptography.
    \begin{itemize}

      \item
        As \cite{newDirections} speculated, any symmetric encryption scheme could be turned into an asymmetric scheme.
        We could hard-code the private key into the encryption algorithm and publicize the obfuscated result.

      \item
        Furthermore, \cite{onThe(Im)possibility} suggests that any asymmetric scheme could be used to construct
        a homomorphic encryption scheme.
        We could write an algorithm that decrypts ciphertexts, performs some operation upon them, and
        encrypts the result.
        If this algorithm could be obfuscated, it could be publicized without leaking the private key.

    \end{itemize}

  \section{Definition of obfuscation}

  \subsection{Virtual black-box}

    The \textit{virtual black-box} property captures the notion of strong hiding behavior we would desire
    in an obfuscator $\obf$.
    An adversary with an obfuscated program $\obf(M)$ can, of course, execute it, which provides the same
    power as oracle access.
    We would like this to be the full extent of the adversary's power; it should not be able to discern
    any additional information about $M$ by inspecting the obfuscated code.

    \cite{onThe(Im)possibility} uses a black-box definition that is ``worst-case'' in the sense that
    it requires an obfuscator to be able to obfuscate any input (in contrast with the approach described
    in Section \ref{sec:sim-bb} that deals with average-case inputs).

    It is not immediately obvious how to formalize the notion of \textit{any additional information} ---
    What properties of the original program need to be hidden?
    Section \ref{sec:no-tm-obf} covers the proof that regardless of how this question is answered,
    a general obfuscator is unattainable.
    The most lenient answer, resulting in the weakest definition of obfuscation, restricts the discussion
    to predicates $P(\cdot)$. If $\obf$ obfuscates, then an adversary given $\obf(M)$ should have no advantage
    at determining $P(M)$ over any algorithm given oracle access to $M$.
    The adversary, due the convoluted nature of $\obf(M)$, is forced to use the subroutine as if it were
    implemented within an opaque container with no means of inspecting the contents.

    The black-box property is stated as follows:
    $\forall\;A$ $\exists\;S$ such that $\forall\;M$,
    \[ \Adv^\vbb_{\obf,A,S,M} \equiv \abs{ \Pr[ A(\obf(M)) ] - \Pr[ S^M(1^n) ] } \]
    is a negligible function of $n$.
    $M$ is a Turing machine with size bounded by an implicit security parameter $n$,
    $S^M$ is a $\ppt$ algorithm with oracle access to the function computed by $M$,
    and the notation ``$A(x)$'' means $A$ accepts (outputs $\one$) on input $x$.

    $S$ has the same output distribution as $A(\obf(M))$, but using only oracle access to $M$.
    This means that every predicate $P(M)$ either can be determined by using $\obf(M)$ as a black box
    or cannot be determined from $\obf(M)$ at all.

  \subsection{Average-case virtual black-box} \label{sec:sim-bb}

    \cite{forCryptoPurposes} presents two alternative black-box definitions.
    These differ from the previous setup in that:
    \begin{itemize}
      \item
        An obfuscator is judged based on its average behavior over inputs $M$
        chosen from some ensemble $\mathcal{M}$.
      \item
        This formulation requires the existence of a simulator which uses only oracle access
        to $M$ to produce an output resembling the distribution $\obf(M)$.
    \end{itemize}

    \textit{Weak definition}: $\forall\;A$ $\exists\;S :$
    $\Adv^\sbvbb_{\mathcal{M},\obf,A,S} \equiv$
    \[\abs{
      \Pr_{M} [ A^{M}(\obf(M)) ] -
      \Pr_{M} [ A^{M}(S^M(\one^n)) ]
    }=\negl(n).\]

    \textit{Strong definition}: $\exists\;S :$ $\forall\;A$
    $\Adv^\ssbvbb_{\mathcal{M},\obf,A,S} \equiv$
    \[\abs{
      \Pr_{M} [ A(M,\obf(M)) ] -
      \Pr_{M} [ A(M,S^M(\one^n)) ]
    }=\negl(n).\]

  \subsection{Correctness}

    We also need to define how the behavior of $\obf(M)$ relates to that of $M$.
    \cite{onThe(Im)possibility} gives two candidate definitions of correctness.
    \begin{itemize}

      \item
        \textit{Perfect functionality}:
        $M$ and $\obf(M)$ compute precisely the same function.
        \[ \forall\;M,x\;(\obf(M))(x) = M(x) \]

      \item
        \textit{Approximate functionality}:
        \[ \forall\;M,x\;\Pr_{\obf(M)}[(\obf(M))(x) = M(x)] \ge 1-\negl(\cdot) \;\footnotemark \]

    \end{itemize}

    \footnotetext{
      Approximate functionality is expressed by \cite{aNoteOn} as
      $\forall\;M\;\Pr_{\obf(M)}[\forall\;x;(\obf(M))(x) = M(x)] \ge 1-\negl(\cdot)$.
      It is unclear to me whether the two expressions meaningfully differ.
    }

    For obfuscation to be useful, we require that the description length and running time
    of $\obf(M)$ must be at most polynomially larger than those of $M$.

  \section{Turing machine obfuscators do not exist} \label{sec:no-tm-obf}

    \cite{onThe(Im)possibility} defines a TM obfuscator as a $\ppt$ algorithm $\obf$ as having the
    virtual black-box property, perfect functionality preservation, and polynomial slowdown.

    Preliminarily, we need to introduce a simple way to compose Turing machines:
    For TMs $f_0$ and $f_1$, their \textit{combination}, denoted by $f_0\#f_1$, is defined such that
    $(f_0\#f_1)(b,x) \equiv f_b(x)$.
    Note that composition and decomposition of combined TMs can be performed
    efficiently, and the transformation approximately preserves running time of the TMs.

    Assuming the existence of an obfuscator, we can reach a contradiction using the following TMs.
    For $n$-bit strings $\alpha$ and $\beta$ chosen at random:
    %
    \begin{align*}
      C_{\alpha,\beta}(x) & \equiv \begin{cases} \beta & x=\alpha \\ \zero^n  & \text{otherwise} \end{cases} \\
      D_{\alpha, \beta}(C) & \equiv \begin{cases} \one & C(\alpha) = \beta \\ \zero & \text{otherwise} \end{cases} \\
      Z(\cdot) & \equiv \zero^n \\
      F_{\alpha, \beta} & \equiv C_{\alpha, \beta} \# D_{\alpha, \beta} \\
      G_{\alpha, \beta} & \equiv Z \# D_{\alpha, \beta} \;\;\;\footnotemark
    \end{align*}
    \footnotetext{
      \cite{onThe(Im)possibility} defines $G_{\alpha,\beta}$ as $Z\#C_{\alpha,\beta}$, but I believe this is an error.
    }

    $D$ is not computable in polytime because the runtime of $C$ may be superpolynomial.
    To work around this problem, we actually define $D$ such that it outputs $\zero$ if $C$
    does not halt within some $\poly(n)$ steps.

    To a machine $S$ with oracle access, $C_{\alpha,\beta}$ is indistinguishable from $Z$,
    because their outputs are identical on all queries except $\alpha$, which is unknown.
    Therefore $\forall$ $S$,
    \[ \abs{\Pr[S^{F_{\alpha,\beta}}] - \Pr[S^{G_{\alpha,\beta}}]} = \negl(n) \;. \]

    Define an adversary $A(f_0\#f_1) \equiv f_1(f_0)$.
    %
    \begin{align*}
      A(\obf(F_{\alpha,\beta})) & = D_{\alpha,\beta}(C_{\alpha,\beta}) = 1\\
      A(\obf(G_{\alpha,\beta})) & = D_{\alpha,\beta}(Z) = 2^{-n}
    \end{align*}

    Therefore either $\Adv^\vbb_{\obf,A,S,F}$ or $\Adv^\vbb_{\obf,A,S,G}$
    exceeds $\frac{1}{2}-\negl(n)$ for all $S$.
    This violates the black-box property, contradicting the assumption that $\obf$ is an obfuscator. \qed

    \section{Circuit obfuscators do not exist}

    \cite{onThe(Im)possibility} procedes to extend this result to show that black-box obfuscation is
    impossible even when we consider only the set of algorithms with efficient circuits.
    This is proven by demonstrating the existence of an \textit{unobfuscatable circuit ensemble}
    with the following properties:%

    \begin{itemize}

      \item
        A circuit from the ensemble can be completely reconstructed given any equivalent circuit.

      \item
        In the average case, a circuit $C$ chosen from the ensemble is difficult to reverse-engineer using an oracle.
        This is shown via the existence of a function $\pi: \text{circuits}\to\bit^*$ such that $\pi(C)\cind U$
        given oracle access to $C$.

    \end{itemize}

    These two statements imply violation of the black-box property for any $\obf(C)$.
    If we take $P(C)$ to be a predicate such as ``the first bit $\pi(C)$'',
    then $A$ can compute $P(C)$ from $\obf(C)$ by inverting the obfuscation to compute $C$ and then applying $\pi$.
    But $S^C$ cannot compute $P(C)$ with probability $\ge \frac{1}{2}+\negl(\cdot)$,
    because $\pi(C)$ is pseudorandom given oracle access to $C$.

    Proof for this fact is elided here, but one is given by \cite{onThe(Im)possibility}
    which is similar to (but a bit lengthier than) the proof for Turing machines.

  \section{Point functions}

    The point function for a value $\alpha$ is defined as
    \[ I_\alpha(x) \equiv \begin{cases} \one & x=\alpha \\ \zero & \text{otherwise} \end{cases} \]

    This class of function is somewhat trivial but not inconsequential.
    Password verification is the evaluation of a point function where $\alpha$ is the correct password,
    and it is desirable for a password-based authentication system to obfuscate its verification
    information to prevent recovery of users' credentials.

    The common solution of applying a one-way hash function to the password prevents recovery of the
    entire password, but it does not necessarily provide complete hiding of the preimage.
    \cite{perfectlyOneWay} presents several constructions of a cryptographic primitive called a
    \textit{perfectly one-way hash function}, consisting of a probabilistic hash $h$ and a verifier
    $V$ such that $V(x, h(x))$ accepts for all possibilities of $h(x)$.
    A perfectly one-way hash does provide point function obfuscation.

  \section{Conclusion}

    The most conclusive result in the area of obfuscation is the impossibility results by
    \cite{onThe(Im)possibility}.

    Point functions are the only area I have seen in which talk of obfuscation seems positive,
    and even on that topic the literature is rife with doubt regarding restrictions on the
    entropy of the function distribution and reliance on non-standard cryptographic assumptions.

    Whether any feasible relaxations of obfuscation can be formulated is unknown.

  \bibliographystyle{amsalpha}

  \bibliography{paper}

\end{document}
